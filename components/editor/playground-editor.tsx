'use client'

import { useCallback, useEffect, useMemo, useRef, useState } from 'react'
import ReactMarkdown from 'react-markdown'
import type { Components } from 'react-markdown'
import remarkGfm from 'remark-gfm'
import rehypeRaw from 'rehype-raw'
import type { PlaygroundPayload } from '@/lib/playgrounds'

type IntentState = {
  status: 'idle' | 'loading' | 'success' | 'error'
  response?: string
  error?: string
}

type IntentTriggerPayload = {
  key: string
  agent: string
  prompt: string
}

type PlaygroundEditorProps = {
  initial?: Partial<PlaygroundPayload> & { previews?: Record<string, string> }
  playgroundId?: string // Optional playground ID for linking media assets
  onChange?: (payload: { markdown: string; blocks: string[]; previews?: Record<string, string>; isGenerating?: boolean }) => void
}

const splitMarkdownBlocks = (markdown: string): string[] => {
  const lines = markdown.split('\n')
  const blocks: string[] = []
  let buffer: string[] = []
  let insideAgent = false

  const flush = () => {
    if (!buffer.length) {
      return
    }

    let result = buffer.join('\n')
    if (!insideAgent) {
      result = result.replace(/\n+$/g, '')
    }

    if (result.trim().length) {
      blocks.push(result)
    }

    buffer = []
  }

  for (const line of lines) {
    const trimmed = line.trim()

    if (!insideAgent && trimmed === ':::') {
      flush()
      insideAgent = true
      buffer.push(':::')
      continue
    }

    if (insideAgent) {
      buffer.push(trimmed === ':::' ? ':::' : line)
      if (trimmed === ':::') {
        insideAgent = false
        flush()
      }
      continue
    }

    buffer.push(line)
    if (trimmed === '') {
      flush()
    }
  }

  flush()
  return blocks
}

const idleIntentState: IntentState = { status: 'idle' }

type IntentPreviewProps = {
  agent: string
  prompt: string
  displayPrompt: string
  buttonText: string
  intentKey: string
  state: IntentState
  onTrigger: (payload: IntentTriggerPayload) => void
}

type ImagePreviewProps = {
  imageKey: string
  agent: string
  imageData?: string
}

const ImagePreview = ({ imageKey, agent, imageData }: ImagePreviewProps) => {
  // Check if it's a URL or data URL
  const isUrl = imageData && typeof imageData === 'string' && imageData.startsWith('/api/media')
  const isDataUrl = imageData && typeof imageData === 'string' && imageData.startsWith('data:image') && imageData.length > 100
  
  if (isUrl || isDataUrl) {
    return (
      <div className="my-3">
        <img
          src={imageData}
          alt={`Generated by ${agent}`}
          className="rounded-lg border border-white/10 max-w-full"
        />
      </div>
    )
  }
  
  if (imageData && imageData.startsWith('‚ö†Ô∏è')) {
    return (
      <div className="my-3 text-sm text-rose-400">
        {imageData}
      </div>
    )
  }
  
  return (
    <div className="my-3 text-sm text-neutral-400">
      üñºÔ∏è <strong>{agent}</strong>: generating image...
    </div>
  )
}

type AudioPreviewProps = {
  audioKey: string
  agent: string
  audioData?: string
}

const AudioPreview = ({ audioKey, agent, audioData }: AudioPreviewProps) => {
  // Check if it's a URL or data URL
  const isUrl = audioData && typeof audioData === 'string' && audioData.startsWith('/api/media')
  const isDataUrl = audioData && typeof audioData === 'string' && (audioData.startsWith('data:audio') || audioData.startsWith('data:audio/')) && audioData.length > 100
  
  if (isUrl || isDataUrl) {
    // Extract MIME type from data URL if needed, otherwise use default
    let mimeType = 'audio/mpeg'
    if (isDataUrl) {
      const mimeTypeMatch = audioData.match(/^data:([^;]+)/)
      mimeType = mimeTypeMatch ? mimeTypeMatch[1] : 'audio/mpeg'
    }
    
    return (
      <div className="my-3">
        <audio controls className="w-full rounded-lg border border-white/10">
          <source src={audioData} type={mimeType} />
          Your browser does not support the audio element.
        </audio>
      </div>
    )
  }
  
  if (audioData && typeof audioData === 'string' && audioData.startsWith('‚ö†Ô∏è')) {
    return (
      <div className="my-3 text-sm text-rose-400">
        {audioData}
      </div>
    )
  }
  
  return (
    <div className="my-3 text-sm text-neutral-400">
      üé§ <strong>{agent}</strong>: generating speech...
    </div>
  )
}

type DefineInputProps = {
  defineKey: string
  name: string
  label: string
  defaultValue: string
  currentValue: string
  onChange: (key: string, value: string) => void
}

const DefineInput = ({ defineKey, name, label, defaultValue, currentValue, onChange }: DefineInputProps) => {
  const [localValue, setLocalValue] = useState(currentValue)

  // Update local value when currentValue prop changes
  useEffect(() => {
    setLocalValue(currentValue)
  }, [currentValue])

  const handleChange = (e: React.ChangeEvent<HTMLInputElement>) => {
    setLocalValue(e.target.value)
  }

  const handleBlur = () => {
    if (localValue !== currentValue) {
      onChange(defineKey, localValue)
    }
  }

  const handleKeyDown = (e: React.KeyboardEvent<HTMLInputElement>) => {
    if (e.key === 'Enter') {
      e.currentTarget.blur()
    }
  }

  return (
    <div className="my-3 flex flex-col gap-2">
      <label className="text-sm font-semibold text-neutral-300">
        {label}
      </label>
      <input
        type="text"
        value={localValue}
        onChange={handleChange}
        onBlur={handleBlur}
        onKeyDown={handleKeyDown}
        placeholder={defaultValue || `Enter ${name}`}
        className="w-full rounded-lg border border-white/10 bg-black/40 px-4 py-2 font-mono text-sm text-neutral-100 placeholder:text-neutral-500 focus:border-violet-400 focus:outline-none"
      />
    </div>
  )
}

const IntentPreview = ({ agent, prompt, displayPrompt, buttonText, intentKey, state, onTrigger }: IntentPreviewProps) => {
  const handleClick = () => {
    if (state.status === 'loading') {
      return
    }
    onTrigger({ key: intentKey, agent, prompt })
  }

  return (
    <div className="mt-3 flex flex-col gap-3">
      <button
        type="button"
        onClick={handleClick}
        disabled={state.status === 'loading'}
        className="inline-flex w-full items-center justify-center gap-2 rounded-full border border-violet-500/40 bg-violet-500/10 px-6 py-3 text-sm font-semibold text-violet-100 transition hover:border-violet-400 hover:bg-violet-500/20 disabled:cursor-not-allowed disabled:opacity-60"
      >
        {state.status === 'loading' ? 'Running‚Ä¶' : buttonText}
      </button>
      {state.status === 'error' && state.error ? (
        <p className="text-xs text-rose-400">{state.error}</p>
      ) : null}
      {state.status === 'success' && state.response ? (
        <div className="rounded-lg border border-white/10 bg-black/40 p-3 text-sm text-neutral-200">
          <ReactMarkdown
            remarkPlugins={[remarkGfm]}
            rehypePlugins={[rehypeRaw]}
            components={{
              img({ src, alt, ...props }: any) {
                // Validate src is a non-empty string
                if (!src || typeof src !== 'string' || src.trim() === '') {
                  return null
                }
                // For data URLs (generated images), ensure they're valid
                if (src.startsWith('data:image')) {
                  if (src.length < 100) {
                    return null
                  }
                }
                return (
                  <img
                    src={src}
                    alt={alt || 'Generated image'}
                    className="rounded-lg border border-white/10 max-w-full"
                    {...props}
                  />
                )
              },
            }}
          >
            {state.response}
          </ReactMarkdown>
        </div>
      ) : null}
    </div>
  )
}

const starterBlocks = [
  `::: 
@define[Wallet](3NAseqQ76ATx6E9iG8EztpGS1ofgt3URvGSZf965XLeA)

@mcp[SolanaMCP](https://mcp.solana.com/mcp)
**Description:** Solana MCP service for protocol metadata, pricing, and account enrichment.

@tool[SolanaBalanceTool](address: String)
**Description:** get solana balance wallet

@ai[BalanceSummarizer](gpt-4o-mini,[SolanaMCP,SolanaBalanceTool])
**Description:** Summarize risks and opportunities across holdings.

:::`,
  '# Portfolio Copilot',
  '> A markdown-native agent that reads on-chain data, builds reports, and suggests next actions.',
  `## üõ†Ô∏è Workflow
1. Fetch balances for {Wallet}
2. Group positions by protocol
3. Generate recommendations via 

~ai[BalanceSummarizer]("""
Summarize risks and opportunities for wallet {Wallet}.
Include:
- At-risk positions
- Suggested rebalancing moves
- Notable protocol exposure
""")`,
  `~intent[BalanceSummarizer](<Summarize risks>,Summarize only the most at-risk positions for {Wallet} in one sentence.)`,
  `~define[Wallet](Wallet Address)`,
]

// Updated regex patterns - supports both unquoted and triple-quoted syntax
// Triple-quoted multi-line: ~ai[Agent]("""multi-line prompt""")
const aiTripleQuoteRegex = /~ai\[(.+?)\]\(\s*"""\s*([\s\S]*?)\s*"""\s*\)/g
// Unquoted multi-line: ~ai[Agent](prompt with
// multiple lines) - must check this before single line, but exclude triple-quoted
// Uses negative lookahead to ensure it doesn't start with """
const aiMultilineRegex = /~ai\[(.+?)\]\(\s*(?!""")([\s\S]*?)\s*\)/g
// Single line: ~ai[Agent](prompt) - only matches if no newlines in prompt
const aiSingleRegex = /~ai\[(.+?)\]\(([^)\n]+)\)/g
const aiImageRegex = /~ai-image\[(.+?)\]\(([^)]+)\)/g
const aiSpeechRegex = /~ai-speech\[(.+?)\]\(([^)]+)\)/g
const defineRegex = /~define\[(.+?)\]\(([^)]+)\)/g
const intentRegex = /~intent\[(.+?)\]\(<([^>]+)>,\s*([\s\S]*?)\)/g
const agentDefineRegex = /^:::\s*\n([\s\S]*?)\n:::\s*$/i

type AiCall = {
  key: string
  agent: string
  prompt: string
  signature?: string
  tool?: {
    name: string
    params: string
  }
  isImage?: boolean
  isSpeech?: boolean
}

type AgentDefinition = {
  kind: string
  name: string
  params: string
  description?: string
  tool?: string
}

const escapeRegExp = (value: string) => value.replace(/[.*+?^${}()|[\]\\]/g, '\\$&')

const substituteDefinitions = (
  text: string,
  definitions: AgentDefinition[],
  userDefines?: Record<string, string>,
  defineNameMap?: Record<string, string>,
) => {
  let result = text

  // First, substitute user-defined values (they take priority)
  if (userDefines && defineNameMap) {
    result = result.replace(/\{([^}]+)\}/g, (match, varName) => {
      // Find the define key for this variable name
      const defineKey = Object.keys(defineNameMap).find(key => defineNameMap[key] === varName)
      if (defineKey && userDefines[defineKey]) {
        return userDefines[defineKey]
      }
      return match
    })
  }

  // Then, substitute agent definitions (only for variables not already replaced)
  result = definitions.reduce((acc, definition) => {
    if (definition.kind.toLowerCase() !== 'define') {
      return acc
    }

    // Only replace if the variable hasn't been replaced by user-defined value
    const varName = definition.name
    const hasUserDefine = userDefines && defineNameMap && 
      Object.keys(defineNameMap).some(key => defineNameMap[key] === varName && userDefines[key])
    
    if (!hasUserDefine) {
      const replacement = definition.params.trim() || definition.name
      return acc.replace(new RegExp(`\\{${escapeRegExp(definition.name)}\\}`, 'g'), replacement)
    }
    return acc
  }, result)

  return result
}

const samplePreviewForAgent = (agent: string) => `ü§ñ ${agent.trim()}: thinking‚Ä¶`
const normalizePrompt = (prompt: string) => prompt.replace(/\r\n/g, '\n').trim()
const escapeAttribute = (value: string) =>
  value
    .replace(/&/g, '&amp;')
    .replace(/"/g, '&quot;')
    .replace(/'/g, '&#39;')
    .replace(/</g, '&lt;')
    .replace(/>/g, '&gt;')

const encodeDataAttribute = (value: string) => escapeAttribute(encodeURIComponent(value))
const decodeDataAttribute = (value: unknown) => {
  if (typeof value !== 'string') {
    return ''
  }
  try {
    return decodeURIComponent(value)
  } catch {
    return ''
  }
}

const getDataAttribute = (props: any, name: string) => {
  if (!props) {
    return undefined
  }
  const direct = props[name]
  if (direct !== undefined) {
    return Array.isArray(direct) ? direct[0] : direct
  }
  const nodeProps = props?.node?.properties
  if (nodeProps && nodeProps[name] !== undefined) {
    const value = nodeProps[name]
    return Array.isArray(value) ? value[0] : value
  }
  return undefined
}

const parseAgentDefinitionBlock = (block: string): AgentDefinition[] | null => {
  const match = agentDefineRegex.exec(block.trim())
  if (!match) {
    return null
  }

  const inner = match[1]
  const lines = inner.split('\n')
  const definitions: AgentDefinition[] = []

  let i = 0
  while (i < lines.length) {
    let line = lines[i]?.trim()
    if (!line) {
      i += 1
      continue
    }

    if (!line.startsWith('@')) {
      i += 1
      continue
    }

    const headerMatch = line.match(/^@([^\[]+)\[([^\]]+)\]\(([^)]*)\)/)
    if (!headerMatch) {
      i += 1
      continue
    }

    const [, kindRaw, nameRaw, paramsRaw] = headerMatch
    let description = ''
    let toolRef: string | undefined

    const inlineToolMatch = paramsRaw.match(/tool\s*:\s*\[([^\]]+)\]/i)
    if (inlineToolMatch) {
      toolRef = inlineToolMatch[1].trim()
    }

    i += 1
    while (i < lines.length) {
      const nextLine = lines[i]
      if (!nextLine || nextLine.trim().startsWith('@')) {
        break
      }

      const trimmed = nextLine.trim()
      if (!toolRef) {
        const toolMatch = trimmed.match(/^tool\s*:\s*\[([^\]]+)\]/i)
        if (toolMatch) {
          toolRef = toolMatch[1].trim()
          i += 1
          continue
        }
      }

      description += `${nextLine.trim()} `
      i += 1
    }

    description = description.replace(/\*\*Description:\*\*\s*/i, '').trim()

    definitions.push({
      kind: kindRaw.trim(),
      name: nameRaw.trim(),
      params: paramsRaw.trim(),
      description: description.length ? description : undefined,
      tool: toolRef,
    })
  }

  return definitions
}

const extractAiCalls = (
  block: string,
  index: number,
  definitions: AgentDefinition[],
  userDefines?: Record<string, string>,
  defineNameMap?: Record<string, string>,
): AiCall[] => {
  const calls: AiCall[] = []

  if (parseAgentDefinitionBlock(block)) {
    return calls
  }

  // Process triple-quoted first, then multiline, then single line to avoid duplicates
  const processedKeys = new Set<string>()
  
  // Triple-quoted strings: ~ai[Agent]("""prompt""")
  const tripleQuoteMatches = [...block.matchAll(aiTripleQuoteRegex)]
  tripleQuoteMatches.forEach(match => {
    const [, agent, prompt] = match
    const promptKey = normalizePrompt(prompt)
    const key = `${index}:${agent.trim()}:${promptKey}`
    
    console.log(`[AI Preview] Triple-quote extraction - key: "${key}"`, {
      agent: agent.trim(),
      promptLength: prompt.length,
      promptKey: promptKey.substring(0, 50),
      originalPrompt: prompt.substring(0, 50)
    })
    
    if (processedKeys.has(key)) {
      return
    }
    processedKeys.add(key)
    
    const promptWithDefinitions = substituteDefinitions(prompt, definitions, userDefines, defineNameMap)
    const aiDefinition = definitions.find(
      def => def.kind.toLowerCase() === 'ai' && def.name.toLowerCase() === agent.trim().toLowerCase(),
    )
    const toolDefinition = aiDefinition?.tool
      ? definitions.find(def => def.kind.toLowerCase() === 'tool' && def.name.toLowerCase() === aiDefinition.tool?.toLowerCase())
      : undefined

    calls.push({
      key,
      agent: agent.trim(),
      prompt: promptWithDefinitions,
      signature: aiDefinition?.params,
      tool: toolDefinition
        ? {
            name: toolDefinition.name,
            params: toolDefinition.params,
          }
        : undefined,
    })
  })

  // Unquoted multiline: ~ai[Agent](prompt with
  // multiple lines)
  const multilineMatches = [...block.matchAll(aiMultilineRegex)]
  multilineMatches.forEach(match => {
    const [, agent, prompt] = match
    const promptKey = normalizePrompt(prompt)
    const key = `${index}:${agent.trim()}:${promptKey}`
    
    // Skip if already processed (avoid duplicates)
    if (processedKeys.has(key)) {
      return
    }
    processedKeys.add(key)
    
    const promptWithDefinitions = substituteDefinitions(prompt, definitions, userDefines, defineNameMap)
    const aiDefinition = definitions.find(
      def => def.kind.toLowerCase() === 'ai' && def.name.toLowerCase() === agent.trim().toLowerCase(),
    )
    const toolDefinition = aiDefinition?.tool
      ? definitions.find(def => def.kind.toLowerCase() === 'tool' && def.name.toLowerCase() === aiDefinition.tool?.toLowerCase())
      : undefined

    calls.push({
      key,
      agent: agent.trim(),
      prompt: promptWithDefinitions,
      signature: aiDefinition?.params,
      tool: toolDefinition
        ? {
            name: toolDefinition.name,
            params: toolDefinition.params,
          }
        : undefined,
    })
  })

  const singleMatches = [...block.matchAll(aiSingleRegex)]
  singleMatches.forEach(match => {
    const [, agent, prompt] = match
    const promptKey = normalizePrompt(prompt)
    const key = `${index}:${agent.trim()}:${promptKey}`
    
    // Skip if already processed by multiline regex
    if (processedKeys.has(key)) {
      return
    }
    processedKeys.add(key)
    
    const promptWithDefinitions = substituteDefinitions(prompt, definitions, userDefines, defineNameMap)
    const aiDefinition = definitions.find(
      def => def.kind.toLowerCase() === 'ai' && def.name.toLowerCase() === agent.trim().toLowerCase(),
    )
    const toolDefinition = aiDefinition?.tool
      ? definitions.find(def => def.kind.toLowerCase() === 'tool' && def.name.toLowerCase() === aiDefinition.tool?.toLowerCase())
      : undefined

    calls.push({
      key,
      agent: agent.trim(),
      prompt: promptWithDefinitions,
      signature: aiDefinition?.params,
      tool: toolDefinition
        ? {
            name: toolDefinition.name,
            params: toolDefinition.params,
          }
        : undefined,
    })
  })

  const imageMatches = [...block.matchAll(aiImageRegex)]
  imageMatches.forEach(match => {
    const [, agent, prompt] = match
    const promptWithDefinitions = substituteDefinitions(prompt, definitions, userDefines, defineNameMap)
    const promptKey = normalizePrompt(prompt)

    calls.push({
      key: `image:${index}:${agent}:${promptKey}`,
      agent: agent.trim(),
      prompt: promptWithDefinitions,
      isImage: true,
    })
  })

  const speechMatches = [...block.matchAll(aiSpeechRegex)]
  speechMatches.forEach(match => {
    const [, agent, prompt] = match
    const promptWithDefinitions = substituteDefinitions(prompt, definitions, userDefines, defineNameMap)
    const promptKey = normalizePrompt(prompt)

    calls.push({
      key: `speech:${index}:${agent}:${promptKey}`,
      agent: agent.trim(),
      prompt: promptWithDefinitions,
      isSpeech: true,
    })
  })

  return calls
}

const replaceAiCalls = (
  block: string,
  index: number,
  previews: Record<string, string>,
  previewRef?: React.MutableRefObject<Record<string, string>>,
  definitions?: AgentDefinition[],
  userDefines?: Record<string, string>,
  defineNameMap?: Record<string, string>,
) => {
  if (parseAgentDefinitionBlock(block)) {
    return ''
  }

  let processedBlock = block

  const formatResponse = (agent: string, response: string) => {
    // Check if it's the thinking state - show bot emoji with name
    // The thinking state is exactly: "ü§ñ AgentName: thinking‚Ä¶"
    const thinkingPattern = `ü§ñ ${agent.trim()}: thinking‚Ä¶`
    if (response === thinkingPattern || response === `ü§ñ **${agent.trim()}**: thinking‚Ä¶`) {
      return `ü§ñ **${agent.trim()}**: thinking‚Ä¶`
    }
    // Check if response is an error message
    if (response.startsWith('‚ö†Ô∏è')) {
      return response
    }
    // After generation, the response is just the content (no bot name prefix)
    // If response exists and is not the thinking pattern, show it
    if (response && response !== thinkingPattern) {
      return response
    }
    // Fallback to thinking state
    return `ü§ñ **${agent.trim()}**: thinking‚Ä¶`
  }

  // Process triple-quoted first, then multiline, then single line to avoid duplicates
  const processedKeys = new Set<string>()
  
  // Triple-quoted strings: ~ai[Agent]("""prompt""")
  const tripleQuoteMatches = [...processedBlock.matchAll(aiTripleQuoteRegex)]
  tripleQuoteMatches.forEach(match => {
    const [fullMatch, agent, prompt] = match
    const normalizedPrompt = normalizePrompt(prompt)
    const key = `${index}:${agent.trim()}:${normalizedPrompt}`
    if (!processedKeys.has(key)) {
      processedKeys.add(key)
      // Check both state and ref for the latest preview
      const refOutput = previewRef?.current?.[key]
      const stateOutput = previews[key]
      const output = refOutput ?? stateOutput
      console.log(`[AI Preview] Triple-quote rendering - key: "${key}"`, {
        hasRefOutput: !!refOutput,
        hasStateOutput: !!stateOutput,
        refOutputPreview: refOutput?.substring(0, 50) || 'none',
        stateOutputPreview: stateOutput?.substring(0, 50) || 'none',
        outputLength: output?.length || 0,
        outputPreview: output?.substring(0, 50) || 'none',
        normalizedPrompt: normalizedPrompt.substring(0, 50),
        allRefKeys: Object.keys(previewRef?.current || {}),
        allStateKeys: Object.keys(previews)
      })
      if (!output) {
        // No preview yet, show thinking state
        processedBlock = processedBlock.replace(fullMatch, formatResponse(agent, samplePreviewForAgent(agent)))
      } else {
        // We have a preview, format it
        processedBlock = processedBlock.replace(fullMatch, formatResponse(agent, output))
      }
    }
  })

  // Unquoted multiline: ~ai[Agent](prompt with
  // multiple lines)
  const multilineMatches = [...processedBlock.matchAll(aiMultilineRegex)]
  multilineMatches.forEach(match => {
    const [fullMatch, agent, prompt] = match
      const key = `${index}:${agent.trim()}:${normalizePrompt(prompt)}`
      if (!processedKeys.has(key)) {
        processedKeys.add(key)
        // Check both state and ref for the latest preview
        const output = previewRef?.current?.[key] ?? previews[key]
        if (!output) {
          // No preview yet, show thinking state
          processedBlock = processedBlock.replace(fullMatch, formatResponse(agent, samplePreviewForAgent(agent)))
        } else {
          // We have a preview, format it
          console.log(`[AI Preview] Found preview for key: "${key}"`, { outputLength: output.length, outputPreview: output.substring(0, 50) })
          processedBlock = processedBlock.replace(fullMatch, formatResponse(agent, output))
        }
      }
  })

  processedBlock = processedBlock.replace(aiSingleRegex, (match, agent: string, prompt: string) => {
    const key = `${index}:${agent.trim()}:${normalizePrompt(prompt)}`
    // Skip if already processed
    if (processedKeys.has(key)) {
      return match
    }
    // Check both state and ref for the latest preview
    const output = previewRef?.current?.[key] ?? previews[key]
    if (!output) {
      // No preview yet, show thinking state
      return formatResponse(agent, samplePreviewForAgent(agent))
    } else {
      // We have a preview, format it
      return formatResponse(agent, output)
    }
  })

  processedBlock = processedBlock.replace(aiImageRegex, (_, agent: string, prompt: string) => {
    const key = `image:${index}:${agent}:${normalizePrompt(prompt)}`
    const output = previews[key]
    // Use custom HTML element that will be replaced with React component
    const keyAttr = encodeDataAttribute(key)
    const agentAttr = encodeDataAttribute(agent.trim())
    const imageDataAttr = output ? encodeDataAttribute(output) : ''
    return `\n<ai-image data-key="${keyAttr}" data-agent="${agentAttr}" data-image="${imageDataAttr}"></ai-image>\n`
  })

  processedBlock = processedBlock.replace(aiSpeechRegex, (_, agent: string, prompt: string) => {
    const key = `speech:${index}:${agent}:${normalizePrompt(prompt)}`
    const output = previews[key]
    // Use custom HTML element that will be replaced with React component
    const keyAttr = encodeDataAttribute(key)
    const agentAttr = encodeDataAttribute(agent.trim())
    const audioDataAttr = output ? encodeDataAttribute(output) : ''
    return `\n<ai-speech data-key="${keyAttr}" data-agent="${agentAttr}" data-audio="${audioDataAttr}"></ai-speech>\n`
  })

  processedBlock = processedBlock.replace(defineRegex, (_, name: string, label: string) => {
    const key = `define:${index}:${name}`
    // Get default value from agent definitions if available
    const agentDefine = definitions?.find(
      def => def.kind.toLowerCase() === 'define' && def.name.toLowerCase() === name.trim().toLowerCase()
    )
    const defaultValue = agentDefine ? (agentDefine.params.trim() || '') : ''
    
    const keyAttr = encodeDataAttribute(key)
    const nameAttr = encodeDataAttribute(name.trim())
    const labelAttr = encodeDataAttribute(label.trim())
    const defaultValueAttr = encodeDataAttribute(defaultValue)
    return `\n<define-input data-key="${keyAttr}" data-name="${nameAttr}" data-label="${labelAttr}" data-default="${defaultValueAttr}"></define-input>\n`
  })

  processedBlock = processedBlock.replace(intentRegex, (_, agent: string, buttonText: string, prompt: string) => {
    const normalizedAgent = agent.trim()
    const normalizedButtonText = buttonText.trim()
    const normalizedPrompt = prompt.trim()
    const promptKey = normalizePrompt(normalizedPrompt)
    const key = `${index}:${normalizedAgent}:${promptKey}`
    const promptWithDefinitions = substituteDefinitions(normalizedPrompt, definitions ?? [], userDefines, defineNameMap)

    const keyAttr = encodeDataAttribute(key)
    const agentAttr = encodeDataAttribute(normalizedAgent)
    const buttonTextAttr = encodeDataAttribute(normalizedButtonText)
    const rawPromptAttr = encodeDataAttribute(normalizedPrompt)
    const renderedPromptAttr = encodeDataAttribute(promptWithDefinitions)

    return `\n<intent-button data-key="${keyAttr}" data-agent="${agentAttr}" data-button-text="${buttonTextAttr}" data-prompt="${rawPromptAttr}" data-rendered="${renderedPromptAttr}"></intent-button>\n`
  })

  return substituteDefinitions(processedBlock, definitions ?? [], userDefines, defineNameMap)
}

export const PlaygroundEditor = ({ initial, playgroundId, onChange }: PlaygroundEditorProps) => {
  const [markdown, setMarkdown] = useState(initial?.markdown ?? starterBlocks.join('\n\n'))
  const blockList = useMemo(() => splitMarkdownBlocks(markdown), [markdown])
  const agentDefinitions = useMemo(() => {
    const definitions = blockList
      .map(block => parseAgentDefinitionBlock(block))
      .filter((def): def is AgentDefinition[] => Boolean(def))
      .flat()
    return definitions
  }, [blockList])
  const mcpDefinitions = useMemo(
    () => agentDefinitions.filter(def => def.kind.toLowerCase() === 'mcp'),
    [agentDefinitions],
  )
  const blockEntries = useMemo(() => {
    const entries: { block: string; index: number }[] = []
    blockList.forEach((block, index) => {
      if (!parseAgentDefinitionBlock(block)) {
        entries.push({ block, index })
      }
    })
    return entries
  }, [blockList])
  const [dragIndex, setDragIndex] = useState<number | null>(null)
  
  // Initialize previews with placeholders for all AI calls on first render
  const initialPreviews = useMemo(() => {
    const previews: Record<string, string> = {}
    blockList.forEach((block, index) => {
      extractAiCalls(block, index, agentDefinitions, {}, {}).forEach(call => {
        if (!call.isImage && !call.isSpeech) {
          previews[call.key] = samplePreviewForAgent(call.agent)
        }
      })
    })
    return previews
  }, [blockList, agentDefinitions])
  
  // Initialize with saved previews if available, otherwise use initial placeholders
  const savedPreviews = initial?.previews || {}
  const [previewMap, setPreviewMap] = useState<Record<string, string>>({ ...initialPreviews, ...savedPreviews })
  const previewRef = useRef<Record<string, string>>({ ...initialPreviews, ...savedPreviews })
  const [intentStates, setIntentStates] = useState<Record<string, IntentState>>({})
  const [userDefines, setUserDefines] = useState<Record<string, string>>({})
  const [isGenerating, setIsGenerating] = useState(false)
  const prevMarkdownRef = useRef<string>(markdown)

  // Extract define calls and initialize userDefines
  const defineCalls = useMemo(() => {
    const defines: Array<{ key: string; name: string; label: string; defaultValue: string }> = []
    blockList.forEach((block, index) => {
      const matches = [...block.matchAll(defineRegex)]
      matches.forEach(match => {
        const [, name, label] = match
        const key = `define:${index}:${name.trim()}`
        // Get default value from agent definitions if available
        const agentDefine = agentDefinitions.find(
          def => def.kind.toLowerCase() === 'define' && def.name.toLowerCase() === name.trim().toLowerCase()
        )
        const defaultValue = agentDefine ? (agentDefine.params.trim() || '') : ''
        defines.push({ key, name: name.trim(), label: label.trim(), defaultValue })
      })
    })
    return defines
  }, [blockList, agentDefinitions])

  // Initialize userDefines with default values from agent definitions
  useEffect(() => {
    const initialDefines: Record<string, string> = {}
    defineCalls.forEach(({ key, defaultValue }) => {
      if (!(key in userDefines) && defaultValue) {
        initialDefines[key] = defaultValue
      }
    })
    if (Object.keys(initialDefines).length > 0) {
      setUserDefines(prev => ({ ...prev, ...initialDefines }))
    }
  }, [defineCalls])

  const resetPreviews = useCallback(() => {
    previewRef.current = {}
    setPreviewMap({})
    setIntentStates({})
  }, [])

  // Map define keys to variable names for quick lookup
  const defineNameMap = useMemo(() => {
    const map: Record<string, string> = {}
    defineCalls.forEach(({ key, name }) => {
      map[key] = name
    })
    return map
  }, [defineCalls])

  // Clear previews for specific AI calls that changed
  const clearChangedPreviews = useCallback((oldMarkdown: string, newMarkdown: string) => {
    const oldBlocks = splitMarkdownBlocks(oldMarkdown)
    const newBlocks = splitMarkdownBlocks(newMarkdown)
    
    // Extract all AI calls from old and new markdown
    // Use a composite key: blockIndex:callType:agent to identify calls
    const oldCalls = new Map<string, { key: string; prompt: string; blockIndex: number; callType: string }>()
    const newCalls = new Map<string, { key: string; prompt: string; blockIndex: number; callType: string }>()
    
    oldBlocks.forEach((block, index) => {
      extractAiCalls(block, index, agentDefinitions, userDefines, defineNameMap).forEach(call => {
        const callType = call.isImage ? 'image' : call.isSpeech ? 'speech' : 'text'
        const positionKey = `${index}:${callType}:${call.agent}`
        oldCalls.set(positionKey, { key: call.key, prompt: call.prompt, blockIndex: index, callType })
      })
    })
    
    newBlocks.forEach((block, index) => {
      extractAiCalls(block, index, agentDefinitions, userDefines, defineNameMap).forEach(call => {
        const callType = call.isImage ? 'image' : call.isSpeech ? 'speech' : 'text'
        const positionKey = `${index}:${callType}:${call.agent}`
        newCalls.set(positionKey, { key: call.key, prompt: call.prompt, blockIndex: index, callType })
      })
    })
    
    // Find changed calls (same position and agent, but different prompt/key)
    const changedKeys = new Set<string>()
    
    newCalls.forEach((newCall, positionKey) => {
      const oldCall = oldCalls.get(positionKey)
      if (oldCall && oldCall.key !== newCall.key) {
        // The prompt changed, so the key changed - clear the old preview
        changedKeys.add(newCall.key)
        // Also clear the old key if it still exists
        if (previewRef.current[oldCall.key]) {
          delete previewRef.current[oldCall.key]
        }
      }
    })
    
    // Also check for new calls (not in old)
    newCalls.forEach((newCall, positionKey) => {
      if (!oldCalls.has(positionKey)) {
        changedKeys.add(newCall.key)
      }
    })
    
    // Clear only the changed previews
    if (changedKeys.size > 0) {
      setPreviewMap(prev => {
        const updated = { ...prev }
        changedKeys.forEach(key => {
          delete updated[key]
        })
        return updated
      })
      
      changedKeys.forEach(key => {
        delete previewRef.current[key]
      })
    }
  }, [agentDefinitions, userDefines, defineNameMap])

  const handleDefineChange = useCallback((key: string, value: string) => {
    setUserDefines(prev => {
      const updated = { ...prev, [key]: value }
      // Get the variable name for this define key
      const varName = defineNameMap[key]
      if (varName) {
        // Only clear previews that use this variable
        const varPattern = new RegExp(`\\{${escapeRegExp(varName)}\\}`)
        setPreviewMap(prevMap => {
          const newMap: Record<string, string> = {}
          Object.keys(prevMap).forEach(previewKey => {
            // Check if this preview's original prompt contains the variable
            // The preview key format is: "index:agent:promptKey" or "image:index:agent:promptKey" or "speech:index:agent:promptKey"
            // We need to find the original block and check if the prompt uses this variable
            let shouldRegenerate = false
            for (let blockIndex = 0; blockIndex < blockList.length; blockIndex++) {
              const block = blockList[blockIndex]
              // Check all AI call patterns
              const allMatches = [
                ...block.matchAll(aiTripleQuoteRegex),
                ...block.matchAll(aiSingleRegex),
                ...block.matchAll(aiMultilineRegex),
                ...block.matchAll(aiImageRegex),
                ...block.matchAll(aiSpeechRegex),
              ]
              
              for (const match of allMatches) {
                const [, agent, prompt] = match
                const promptKey = normalizePrompt(prompt)
                // Check if this matches the preview key pattern
                const possibleKeys = [
                  `${blockIndex}:${agent.trim()}:${promptKey}`,
                  `image:${blockIndex}:${agent.trim()}:${promptKey}`,
                  `speech:${blockIndex}:${agent.trim()}:${promptKey}`,
                ]
                
                if (possibleKeys.includes(previewKey) && varPattern.test(prompt)) {
                  shouldRegenerate = true
                  break
                }
              }
              if (shouldRegenerate) break
            }
            
            if (!shouldRegenerate) {
              newMap[previewKey] = prevMap[previewKey]
            } else {
              // Remove from previewRef so it regenerates
              delete previewRef.current[previewKey]
            }
          })
          previewRef.current = { ...previewRef.current, ...newMap }
          return newMap
        })
      } else {
        // If we can't find the variable name, clear all previews
        previewRef.current = {}
        setPreviewMap({})
      }
      setIntentStates({})
      return updated
    })
  }, [defineNameMap, blockList])

  const handleIntentTrigger = useCallback(
    async ({ key, agent, prompt }: IntentTriggerPayload) => {
      const aiDefinition = agentDefinitions.find(
        def => def.kind.toLowerCase() === 'ai' && def.name.toLowerCase() === agent.trim().toLowerCase(),
      )
      const toolDefinition = aiDefinition?.tool
        ? agentDefinitions.find(
            def => def.kind.toLowerCase() === 'tool' && def.name.toLowerCase() === aiDefinition.tool?.toLowerCase(),
          )
        : undefined

      const config =
        aiDefinition || toolDefinition
          ? {
              signature: aiDefinition?.params,
              tool: toolDefinition
                ? {
                    name: toolDefinition.name,
                    params: toolDefinition.params,
                  }
                : undefined,
            }
          : undefined

      const promptWithDefinitions = substituteDefinitions(prompt, agentDefinitions, userDefines, defineNameMap)

      setIntentStates(prev => ({
        ...prev,
        [key]: { status: 'loading' },
      }))

      try {
        const response = await fetch('/api/generate', {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({
            type: 'text',
            bot: agent,
            prompt: promptWithDefinitions,
            ...(config ? { config } : {}),
            ...(mcpDefinitions.length
              ? { mcp: mcpDefinitions.map(definition => ({ name: definition.name, params: definition.params })) }
              : {}),
          }),
        })

        if (!response.ok) {
          throw new Error(`Request failed with status ${response.status}`)
        }

        const payload: { content?: string } = await response.json()
        const content = payload.content?.trim() ?? ''

        setIntentStates(prev => ({
          ...prev,
          [key]: {
            status: content.length ? 'success' : 'error',
            response: content.length ? content : undefined,
            error: content.length ? undefined : 'No response content',
          },
        }))
      } catch (error) {
        setIntentStates(prev => ({
          ...prev,
          [key]: {
            status: 'error',
            error: error instanceof Error ? error.message : 'Failed to run intent.',
          },
        }))
      }
    },
    [agentDefinitions, mcpDefinitions, userDefines],
  )

  const markdownComponents = useMemo(
    () =>
      ({
        code({ inline, children, ...props }: any) {
          if (inline) {
            return (
              <code className="font-mono text-xs text-violet-200" {...props}>
                {children}
              </code>
            )
          }

          return (
            <code
              className="block whitespace-pre-wrap rounded-md bg-black/40 p-3 font-mono text-xs text-neutral-100"
              {...props}
            >
              {children}
            </code>
          )
        },
        p({ node, children, ...props }: any) {
          const hasCustomElement = Array.isArray(node?.children)
            ? node.children.some((child: any) => 
                child?.tagName === 'intent-button' || child?.tagName === 'ai-image' || child?.tagName === 'ai-speech' || child?.tagName === 'define-input'
              )
            : false
          if (hasCustomElement) {
            const { className, ...rest } = props
            return (
              <div {...rest} className={className}>
                {children}
              </div>
            )
          }
          return (
            <p {...props}>
              {children}
            </p>
          )
        },
        ['define-input']: (props: any) => {
          const keyAttr = decodeDataAttribute(getDataAttribute(props, 'data-key'))
          const nameAttr = decodeDataAttribute(getDataAttribute(props, 'data-name')) || 'Variable'
          const labelAttr = decodeDataAttribute(getDataAttribute(props, 'data-label')) || nameAttr
          const defaultValueAttr = decodeDataAttribute(getDataAttribute(props, 'data-default')) || ''
          const currentValue = userDefines[keyAttr] ?? defaultValueAttr

          return (
            <DefineInput
              key={keyAttr}
              defineKey={keyAttr}
              name={nameAttr}
              label={labelAttr}
              defaultValue={defaultValueAttr}
              currentValue={currentValue}
              onChange={handleDefineChange}
            />
          )
        },
        ['ai-image']: (props: any) => {
          const keyAttr = decodeDataAttribute(getDataAttribute(props, 'data-key'))
          const agentAttr = decodeDataAttribute(getDataAttribute(props, 'data-agent')) || 'ImageGenerator'
          // Always get the latest image data from previewMap (ignore data attribute)
          const imageData = previewMap[keyAttr]

          return (
            <ImagePreview
              key={keyAttr}
              imageKey={keyAttr}
              agent={agentAttr}
              imageData={imageData}
            />
          )
        },
        ['ai-speech']: (props: any) => {
          const keyAttr = decodeDataAttribute(getDataAttribute(props, 'data-key'))
          const agentAttr = decodeDataAttribute(getDataAttribute(props, 'data-agent')) || 'SpeechGenerator'
          // Always get the latest audio data from previewMap (ignore data attribute)
          const audioData = previewMap[keyAttr]

          return (
            <AudioPreview
              key={keyAttr}
              audioKey={keyAttr}
              agent={agentAttr}
              audioData={audioData}
            />
          )
        },
        ['intent-button']: (props: any) => {
          const keyAttr = decodeDataAttribute(getDataAttribute(props, 'data-key'))
          const agentAttr = decodeDataAttribute(getDataAttribute(props, 'data-agent')) || 'Intent'
          const buttonTextAttr = decodeDataAttribute(getDataAttribute(props, 'data-button-text')) || 'Run intent'
          const rawPromptAttr = decodeDataAttribute(getDataAttribute(props, 'data-prompt'))
          const renderedPromptAttr = decodeDataAttribute(getDataAttribute(props, 'data-rendered')) || rawPromptAttr
          const state = intentStates[keyAttr] ?? idleIntentState

          return (
            <IntentPreview
              key={keyAttr}
              agent={agentAttr}
              prompt={rawPromptAttr}
              displayPrompt={renderedPromptAttr}
              buttonText={buttonTextAttr}
              intentKey={keyAttr}
              state={state}
              onTrigger={handleIntentTrigger}
            />
          )
        },
        img({ src, alt, ...props }: any) {
          // Validate src is a non-empty string
          if (!src || typeof src !== 'string' || src.trim() === '') {
            return null
          }
          // For data URLs (generated images), ensure they're valid
          if (src.startsWith('data:image')) {
            if (src.length < 100) {
              return null
            }
          }
          return (
            <img
              src={src}
              alt={alt || 'Generated image'}
              className="rounded-lg border border-white/10 max-w-full"
              {...props}
            />
          )
        },
      } as Components),
    [previewMap, intentStates, handleIntentTrigger, userDefines, handleDefineChange, defineNameMap],
  )

  const handleBlockDragStart = useCallback((index: number) => {
    setDragIndex(index)
  }, [])

  const handleBlockDrop = useCallback(
    (index: number) => {
      if (dragIndex === null || dragIndex === index) {
        setDragIndex(null)
        return
      }

      const nextBlocks = [...blockList]
      const [removed] = nextBlocks.splice(dragIndex, 1)
      nextBlocks.splice(index, 0, removed)

      resetPreviews()
      const nextMarkdown = nextBlocks.join('\n\n')
      setMarkdown(nextMarkdown)
      setDragIndex(null)
      onChange?.({ markdown: nextMarkdown, blocks: nextBlocks, previews: previewRef.current, isGenerating })
    },
    [dragIndex, blockList, onChange, resetPreviews, isGenerating],
  )

  const handleMarkdownChange = useCallback(
    (value: string) => {
      const oldMarkdown = prevMarkdownRef.current
      prevMarkdownRef.current = value
      
      // Only clear previews for changed AI calls, not all of them
      clearChangedPreviews(oldMarkdown, value)
      
      setMarkdown(value)
      onChange?.({ markdown: value, blocks: splitMarkdownBlocks(value), previews: previewRef.current, isGenerating })
    },
    [onChange, clearChangedPreviews, isGenerating],
  )

  useEffect(() => {
    let cancelled = false

    const run = async () => {
      const pending: AiCall[] = []
      const initialPreviews: Record<string, string> = {}

      // First pass: collect all AI calls and set placeholders for new ones only
      blockList.forEach((block, index) => {
        extractAiCalls(block, index, agentDefinitions, userDefines, defineNameMap).forEach(call => {
          const existingPreview = previewRef.current[call.key]
          const isPlaceholder = existingPreview === samplePreviewForAgent(call.agent) || 
                                existingPreview?.includes('thinking‚Ä¶')
          
          console.log(`[AI Preview] Checking call: "${call.key}"`, {
            hasExisting: !!existingPreview,
            isPlaceholder,
            existingPreview: existingPreview?.substring(0, 50),
            agent: call.agent,
            promptPreview: call.prompt.substring(0, 50)
          })
          
          // If no preview exists, or it's just a placeholder, we need to generate it
          if (!existingPreview || isPlaceholder) {
            // Don't set placeholder for images/speech - let the component show "generating..."
            // Only set placeholder for text AI calls
            if (!call.isImage && !call.isSpeech) {
              const placeholder = samplePreviewForAgent(call.agent)
              previewRef.current[call.key] = placeholder
              initialPreviews[call.key] = placeholder
            }
            console.log(`[AI Preview] Adding to pending: "${call.key}"`)
            pending.push(call)
          } else {
            console.log(`[AI Preview] Skipping (already has content): "${call.key}"`)
          }
        })
      })
      
      console.log(`[AI Preview] Total pending calls: ${pending.length}`, pending.map(c => c.key))

      // Set all placeholders at once to trigger a single render (only update if there are new ones)
      if (Object.keys(initialPreviews).length > 0) {
        setPreviewMap(prev => {
          // Only add new previews, don't overwrite existing ones
          const updates: Record<string, string> = {}
          Object.keys(initialPreviews).forEach(key => {
            if (!prev[key]) {
              updates[key] = initialPreviews[key]
            }
          })
          return Object.keys(updates).length > 0 ? { ...prev, ...updates } : prev
        })
      }

      if (!pending.length) {
        setIsGenerating(false)
        return
      }

      setIsGenerating(true)

      for (const call of pending) {
        try {
          if (call.isImage) {
            const response = await fetch('/api/generate', {
              method: 'POST',
              headers: { 'Content-Type': 'application/json' },
              body: JSON.stringify({
                type: 'image',
                bot: call.agent,
                prompt: call.prompt,
                key: call.key,
                playgroundId: playgroundId,
              }),
            })

            if (!response.ok) {
              throw new Error(`Request failed with status ${response.status}`)
            }

            const payload: { image?: string; error?: string } = await response.json()
            const imageData = payload.image

            if (!cancelled) {
              if (imageData && typeof imageData === 'string') {
                // Check if it's a URL (starts with /api/media) or data URL
                const isUrl = imageData.startsWith('/api/media')
                const isDataUrl = imageData.startsWith('data:image')
                
                if (isUrl || (isDataUrl && imageData.length > 100)) {
                  console.log(`Image generated successfully for ${call.key}, ${isUrl ? 'URL' : 'data URL'}: ${isUrl ? imageData : imageData.length + ' chars'}`)
                  setPreviewMap(prev => {
                    const next = { ...prev, [call.key]: imageData }
                    previewRef.current = next
                    return next
                  })
                } else {
                  console.warn(`Image data invalid for ${call.key}: ${isDataUrl ? 'too short' : 'invalid format'}`)
                  setPreviewMap(prev => {
                    const next = { ...prev, [call.key]: `‚ö†Ô∏è ${call.agent}: invalid image data` }
                    previewRef.current = next
                    return next
                  })
                }
              } else {
                const errorMsg = payload.error || 'No image data received'
                console.error(`Image generation failed for ${call.key}:`, errorMsg)
                setPreviewMap(prev => {
                  const next = { ...prev, [call.key]: `‚ö†Ô∏è ${call.agent}: ${errorMsg}` }
                  previewRef.current = next
                  return next
                })
              }
            }
          } else if (call.isSpeech) {
            const response = await fetch('/api/generate', {
              method: 'POST',
              headers: { 'Content-Type': 'application/json' },
              body: JSON.stringify({
                type: 'speech',
                bot: call.agent,
                prompt: call.prompt,
                key: call.key,
                playgroundId: playgroundId,
              }),
            })

            if (!response.ok) {
              throw new Error(`Request failed with status ${response.status}`)
            }

            const payload: { audio?: string; error?: string } = await response.json()
            const audioData = payload.audio

            if (!cancelled) {
              if (audioData && typeof audioData === 'string') {
                // Check if it's a URL (starts with /api/media) or data URL
                const isUrl = audioData.startsWith('/api/media')
                const isDataUrl = audioData.startsWith('data:audio') || audioData.startsWith('data:audio/')
                
                if (isUrl || (isDataUrl && audioData.length > 100)) {
                  console.log(`Speech generated successfully for ${call.key}, ${isUrl ? 'URL' : 'data URL'}: ${isUrl ? audioData : audioData.length + ' chars'}`)
                  setPreviewMap(prev => {
                    const next = { ...prev, [call.key]: audioData }
                    previewRef.current = next
                    return next
                  })
                } else {
                  console.warn(`Audio data invalid for ${call.key}: ${isDataUrl ? 'too short' : 'invalid format'}`)
                  setPreviewMap(prev => {
                    const next = { ...prev, [call.key]: `‚ö†Ô∏è ${call.agent}: invalid audio data` }
                    previewRef.current = next
                    return next
                  })
                }
              } else {
                const errorMsg = payload.error || 'No audio data received'
                console.error(`Speech generation failed for ${call.key}:`, errorMsg)
                setPreviewMap(prev => {
                  const next = { ...prev, [call.key]: `‚ö†Ô∏è ${call.agent}: ${errorMsg}` }
                  previewRef.current = next
                  return next
                })
              }
            }
          } else {
            const config =
              call.signature || call.tool
                ? {
                    signature: call.signature,
                    tool: call.tool,
                  }
                : undefined

            const response = await fetch('/api/generate', {
              method: 'POST',
              headers: { 'Content-Type': 'application/json' },
              body: JSON.stringify({
                type: 'text',
                bot: call.agent,
                prompt: call.prompt,
                ...(config ? { config } : {}),
                ...(mcpDefinitions.length
                  ? { mcp: mcpDefinitions.map(definition => ({ name: definition.name, params: definition.params })) }
                  : {}),
              }),
            })

            if (!response.ok) {
              const errorText = await response.text()
              console.error(`API request failed for ${call.key}:`, response.status, errorText)
              throw new Error(`Request failed with status ${response.status}: ${errorText}`)
            }

            const payload: { content?: string; error?: string } = await response.json()
            
            if (!payload.content && !payload.error) {
              console.warn(`No content or error in response for ${call.key}:`, payload)
            }
            
            if (payload.error) {
              if (!cancelled) {
                setPreviewMap(prev => {
                  const next = { ...prev, [call.key]: `‚ö†Ô∏è ${call.agent}: ${payload.error}` }
                  previewRef.current = next
                  return next
                })
              }
            } else {
              const content = payload.content?.trim()
                ? payload.content.trim() // Store content without bot name prefix - formatResponse will handle display
                : `‚ö†Ô∏è ${call.agent}: (no response)`

              if (!cancelled) {
                console.log(`[AI Preview] Updating preview for key: "${call.key}"`, {
                  agent: call.agent,
                  originalPrompt: call.prompt.substring(0, 100),
                  promptKey: normalizePrompt(call.prompt),
                  contentLength: content.length,
                  contentPreview: content.substring(0, 100),
                  allKeys: Object.keys(previewRef.current)
                })
                // Update ref immediately (synchronous)
                previewRef.current[call.key] = content
                setPreviewMap(prev => {
                  const next = { ...prev, [call.key]: content }
                  console.log(`[AI Preview] Preview map updated. Key "${call.key}" now has:`, content.substring(0, 50))
                  return next
                })
              }
            }
          }
        } catch (error) {
          if (!cancelled) {
            setPreviewMap(prev => {
              const next = { ...prev, [call.key]: `‚ö†Ô∏è ${call.agent}: unable to generate preview` }
              previewRef.current[call.key] = next[call.key]
              return next
            })
          }
        }
      }
      
      // All calls completed
      setIsGenerating(false)
    }

    run()

    return () => {
      cancelled = true
      setIsGenerating(false)
    }
  }, [agentDefinitions, blockList, userDefines, mcpDefinitions, defineNameMap])

  // Trigger onChange when previews are updated so they get saved
  // Use a ref to track previous previews to avoid unnecessary calls
  const prevPreviewsRef = useRef<Record<string, string>>({})
  useEffect(() => {
    const previewsChanged = JSON.stringify(previewRef.current) !== JSON.stringify(prevPreviewsRef.current)
    if (previewsChanged && Object.keys(previewRef.current).length > 0) {
      prevPreviewsRef.current = { ...previewRef.current }
      onChange?.({ markdown, blocks: blockList, previews: previewRef.current, isGenerating })
    }
  }, [previewMap, markdown, blockList, isGenerating, onChange])
  
  // Also notify when generation state changes
  useEffect(() => {
    onChange?.({ markdown, blocks: blockList, previews: previewRef.current, isGenerating })
  }, [isGenerating])

  return (
    <section className="flex flex-col gap-4 p-6 lg:p-8">
      <header className="flex items-center justify-between">
        <div>
          <h2 className="text-lg font-semibold text-white">Playground editor</h2>
          <p className="text-sm text-neutral-400">
            Drag blocks to reorganize sections, or edit the raw Markdown to unlock full control.
          </p>
        </div>
      </header>
      <div className="grid gap-6 lg:grid-cols-2">
        <div className="flex flex-col gap-3">
          <h3 className="text-sm font-semibold uppercase tracking-[0.35em] text-neutral-400">Blocks</h3>
          <ul className="space-y-3">
            {blockEntries.map(({ block, index }) => (
              <li
                key={`${block}-${index}`}
                draggable
                onDragStart={() => handleBlockDragStart(index)}
                onDragOver={event => event.preventDefault()}
                onDrop={() => handleBlockDrop(index)}
                className="cursor-move rounded-xl border border-dashed border-violet-500/40 bg-violet-500/5 px-3 py-3 text-sm text-neutral-200 transition hover:border-violet-400/60"
              >
                <div className="prose prose-invert max-w-none prose-headings:text-white prose-p:text-neutral-200 prose-strong:text-white prose-li:text-neutral-200">
                  <ReactMarkdown
                    remarkPlugins={[remarkGfm]}
                    rehypePlugins={[rehypeRaw]}
                    components={markdownComponents}
                  >
                    {replaceAiCalls(block, index, previewMap, previewRef, agentDefinitions, userDefines, defineNameMap)}
                  </ReactMarkdown>
                </div>
              </li>
            ))}
          </ul>
        </div>
        <div className="flex flex-col gap-3">
          <h3 className="text-sm font-semibold uppercase tracking-[0.35em] text-neutral-400">Markdown</h3>
          <textarea
            value={markdown}
            onChange={event => handleMarkdownChange(event.target.value)}
            rows={35}
            className="w-full resize-y rounded-xl border border-white/10 bg-black/40 p-4 font-mono text-sm text-neutral-100 focus:border-violet-400 focus:outline-none"
          />
        </div>
      </div>
    </section>
  )
}


